{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girinath18/AI_Headshot_RG/blob/headshots/Nokia2API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JciKDOeft8qc",
        "outputId": "d201f0ad-4142-4b93-be89-00c1dae1b894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "hgrXj9DzuqAP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.set_auth_token(\"2grhewRoUtjHE4SVcxmbIPobZ9e_7KdSgCrcQoczPKpuwUtpm\")\n",
        "public_url = ngrok.connect(5000).public_url"
      ],
      "metadata": {
        "id": "2zwX28_susTU",
        "outputId": "1fc615e0-e9ee-4cd8-f4c5-8368a78f9d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/girinath18/roop.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp9dmAxtuwZk",
        "outputId": "aaf848ec-570e-41d9-a02f-26e8457f606d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'roop'...\n",
            "remote: Enumerating objects: 1540, done.\u001b[K\n",
            "remote: Total 1540 (delta 0), reused 0 (delta 0), pack-reused 1540\u001b[K\n",
            "Receiving objects: 100% (1540/1540), 97.43 MiB | 48.01 MiB/s, done.\n",
            "Resolving deltas: 100% (917/917), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask_ngrok\n",
        "!pip install onnxruntime\n",
        "!pip install customtkinter\n",
        "!pip install torch torchvision\n",
        "!pip install flask\n",
        "!pip install pyngrok --upgrade\n",
        "!pip install --upgrade pyngrok\n",
        "!pip install -r /content/roop/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h5b7HK9Ju0Ad",
        "outputId": "7e0418c9-1e65-46a2-c4d8-790c5c4e62d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask_ngrok) (2.1.5)\n",
            "Installing collected packages: flask_ngrok\n",
            "Successfully installed flask_ngrok-0.0.25\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.18.0\n",
            "Collecting customtkinter\n",
            "  Downloading customtkinter-5.2.2-py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting darkdetect (from customtkinter)\n",
            "  Downloading darkdetect-0.8.0-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from customtkinter) (24.0)\n",
            "Installing collected packages: darkdetect, customtkinter\n",
            "Successfully installed customtkinter-5.2.2 darkdetect-0.8.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Ignoring tkinterdnd2-universal: markers 'sys_platform == \"darwin\" and platform_machine == \"arm64\"' don't match your environment\n",
            "Ignoring onnxruntime: markers 'python_version != \"3.9\" and sys_platform == \"darwin\" and platform_machine != \"arm64\"' don't match your environment\n",
            "Ignoring onnxruntime-coreml: markers 'python_version == \"3.9\" and sys_platform == \"darwin\" and platform_machine != \"arm64\"' don't match your environment\n",
            "Ignoring onnxruntime-silicon: markers 'sys_platform == \"darwin\" and platform_machine == \"arm64\"' don't match your environment\n",
            "Collecting numpy==1.24.3 (from -r /content/roop/requirements.txt (line 3))\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.8.0.74 (from -r /content/roop/requirements.txt (line 4))\n",
            "  Downloading opencv_python-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx==1.14.0 (from -r /content/roop/requirements.txt (line 5))\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting insightface==0.7.3 (from -r /content/roop/requirements.txt (line 6))\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil==5.9.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/roop/requirements.txt (line 7)) (5.9.5)\n",
            "Collecting tk==0.1.0 (from -r /content/roop/requirements.txt (line 8))\n",
            "  Downloading tk-0.1.0-py3-none-any.whl (3.9 kB)\n",
            "Collecting customtkinter==5.2.0 (from -r /content/roop/requirements.txt (line 9))\n",
            "  Downloading customtkinter-5.2.0-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.6/295.6 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tkinterdnd2==0.3.0 (from -r /content/roop/requirements.txt (line 10))\n",
            "  Downloading tkinterdnd2-0.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.7/386.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow==10.0.0 (from -r /content/roop/requirements.txt (line 12))\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime-gpu==1.15.1 (from -r /content/roop/requirements.txt (line 16))\n",
            "  Downloading onnxruntime_gpu-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.13.0 (from -r /content/roop/requirements.txt (line 17))\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opennsfw2==0.10.2 (from -r /content/roop/requirements.txt (line 18))\n",
            "  Downloading opennsfw2-0.10.2-py3-none-any.whl (12 kB)\n",
            "Collecting protobuf==4.23.4 (from -r /content/roop/requirements.txt (line 19))\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.65.0 (from -r /content/roop/requirements.txt (line 20))\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gfpgan==1.3.8 (from -r /content/roop/requirements.txt (line 21))\n",
            "  Downloading gfpgan-1.3.8-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx==1.14.0->-r /content/roop/requirements.txt (line 5)) (4.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (0.19.3)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (3.0.10)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: darkdetect in /usr/local/lib/python3.10/dist-packages (from customtkinter==5.2.0->-r /content/roop/requirements.txt (line 9)) (0.8.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.15.1->-r /content/roop/requirements.txt (line 16)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.15.1->-r /content/roop/requirements.txt (line 16)) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.15.1->-r /content/roop/requirements.txt (line 16)) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.15.1->-r /content/roop/requirements.txt (line 16)) (1.12)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (1.6.3)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17))\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (1.64.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (3.9.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17))\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17))\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17))\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (2.4.0)\n",
            "Collecting typing-extensions>=3.6.2.1 (from onnx==1.14.0->-r /content/roop/requirements.txt (line 5))\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (0.37.0)\n",
            "Requirement already satisfied: gdown>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from opennsfw2==0.10.2->-r /content/roop/requirements.txt (line 18)) (5.1.0)\n",
            "Collecting basicsr>=1.4.2 (from gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21))\n",
            "  Downloading basicsr-1.4.2.tar.gz (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting facexlib>=0.2.5 (from gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21))\n",
            "  Downloading facexlib-0.3.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lmdb (from gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21))\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (6.0.1)\n",
            "Collecting tb-nightly (from gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21))\n",
            "  Downloading tb_nightly-2.17.0a20240526-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (0.18.0+cu121)\n",
            "Collecting yapf (from gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21))\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (0.43.0)\n",
            "Collecting addict (from basicsr>=1.4.2->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (0.18.3)\n",
            "Collecting filterpy (from facexlib>=0.2.5->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21))\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (0.58.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.2.0->opennsfw2==0.10.2->-r /content/roop/requirements.txt (line 18)) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.2.0->opennsfw2==0.10.2->-r /content/roop/requirements.txt (line 18)) (3.14.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (2024.5.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (1.6.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17))\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (3.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (2024.2.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch>=1.7 (from gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.3.0%2Bcu118-cp310-cp310-linux_x86_64.whl (839.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m839.6/839.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.2%2Bcu118-cp310-cp310-linux_x86_64.whl (819.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.2/819.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.1%2Bcu118-cp310-cp310-linux_x86_64.whl (819.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.2/819.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.0%2Bcu118-cp310-cp310-linux_x86_64.whl (811.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.7/811.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.2%2Bcu118-cp310-cp310-linux_x86_64.whl (2325.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m548.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (2023.6.0)\n",
            "Collecting triton==2.1.0 (from torch>=1.7->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21))\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (4.9.0.80)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime-gpu==1.15.1->-r /content/roop/requirements.txt (line 16)) (10.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (0.2.13)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu==1.15.1->-r /content/roop/requirements.txt (line 16)) (1.3.0)\n",
            "Collecting torchvision (from gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21))\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (7.1.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (4.2.2)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (2.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (3.18.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (2.1.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.2.0->opennsfw2==0.10.2->-r /content/roop/requirements.txt (line 18)) (2.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->facexlib>=0.2.5->gfpgan==1.3.8->-r /content/roop/requirements.txt (line 21)) (0.41.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->insightface==0.7.3->-r /content/roop/requirements.txt (line 6)) (1.7.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/roop/requirements.txt (line 17)) (3.2.2)\n",
            "Building wheels for collected packages: insightface, basicsr, filterpy\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp310-cp310-linux_x86_64.whl size=1054143 sha256=db16b38b7336e797b47eaabe18a4357444edbc6a1b209ab0d7186eebef303226\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/d0/80/e3773fb8b6d1cca87ea1d33d9b1f20a223a6493c896da249b5\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214818 sha256=939b41f8808e00e34b977aa2179127759e0a045fb3720468718339437f7ecc45\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/83/99/2d8437cc652a01af27df5ff037a4075e95b52d67705c5f30ca\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=40e1dbf9bb3eef15d2910913936b560d019157688b255f91d5c5eb5974d76188\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built insightface basicsr filterpy\n",
            "Installing collected packages: tk, lmdb, addict, typing-extensions, triton, tqdm, tkinterdnd2, tensorflow-estimator, protobuf, pillow, numpy, keras, gast, customtkinter, yapf, torch, tb-nightly, opencv-python, onnxruntime-gpu, onnx, torchvision, google-auth-oauthlib, tensorboard, filterpy, basicsr, tensorflow, facexlib, opennsfw2, insightface, gfpgan\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.11.0\n",
            "    Uninstalling typing_extensions-4.11.0:\n",
            "      Successfully uninstalled typing_extensions-4.11.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: customtkinter\n",
            "    Found existing installation: customtkinter 5.2.2\n",
            "    Uninstalling customtkinter-5.2.2:\n",
            "      Successfully uninstalled customtkinter-5.2.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.0+cu121\n",
            "    Uninstalling torchvision-0.18.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.0+cu121\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.30 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
            "pydantic 2.7.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.18.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.23.4 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.13.0 which is incompatible.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.1.2+cu118 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.1.2+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed addict-2.4.0 basicsr-1.4.2 customtkinter-5.2.0 facexlib-0.3.0 filterpy-1.4.5 gast-0.4.0 gfpgan-1.3.8 google-auth-oauthlib-1.0.0 insightface-0.7.3 keras-2.13.1 lmdb-1.4.1 numpy-1.24.3 onnx-1.14.0 onnxruntime-gpu-1.15.1 opencv-python-4.8.0.74 opennsfw2-0.10.2 pillow-10.0.0 protobuf-4.23.4 tb-nightly-2.17.0a20240526 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tk-0.1.0 tkinterdnd2-0.3.0 torch-2.1.2+cu118 torchvision-0.16.2+cu118 tqdm-4.65.0 triton-2.1.0 typing-extensions-4.5.0 yapf-0.40.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              },
              "id": "fc27fe5a9ed846c9ba97b81dc5aeb128"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **To changing the directory**"
      ],
      "metadata": {
        "id": "r1NMw57fw7oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd roop"
      ],
      "metadata": {
        "id": "atUmT6y9Gk94",
        "outputId": "fde8d0bf-637e-4af2-bcc9-ffb34ea5b17e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/roop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic logic code but working code API script**"
      ],
      "metadata": {
        "id": "QkMCMFKtw0SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import os\n",
        "import shutil\n",
        "import logging\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "\n",
        "TEMPLATES_FOLDER_PATH = \"/content/drive/MyDrive/template/captain/Female\"\n",
        "\n",
        "def face_swap(source_image_folder, output_base_folder):\n",
        "    try:\n",
        "\n",
        "        output_folder = os.path.join(output_base_folder, \"(Outputs)\")\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        logging.info(f\"Output folder created at: {output_folder}\")\n",
        "\n",
        "\n",
        "        source_images = os.listdir(source_image_folder)\n",
        "        if not source_images:\n",
        "            logging.error(\"No source images found.\")\n",
        "            return\n",
        "        logging.info(f\"Found {len(source_images)} source images.\")\n",
        "\n",
        "\n",
        "        template_images = os.listdir(TEMPLATES_FOLDER_PATH)\n",
        "        if not template_images:\n",
        "            logging.error(\"No template images found.\")\n",
        "            return\n",
        "        logging.info(f\"Found {len(template_images)} template images.\")\n",
        "\n",
        "\n",
        "        for source_image_name in source_images:\n",
        "            source_image_path = os.path.join(source_image_folder, source_image_name)\n",
        "\n",
        "\n",
        "            if os.path.isfile(source_image_path):\n",
        "                logging.info(f\"Processing source image: {source_image_name}\")\n",
        "\n",
        "                processed_image_paths = set()\n",
        "\n",
        "                for target_image_name in template_images:\n",
        "                    target_image_path = os.path.join(TEMPLATES_FOLDER_PATH, target_image_name)\n",
        "\n",
        "\n",
        "                    if os.path.isfile(target_image_path):\n",
        "                        logging.info(f\"Processing target image: {target_image_name}\")\n",
        "\n",
        "                        output_image_path = os.path.join(output_folder, f\"{source_image_name}_{target_image_name}\")\n",
        "                        if output_image_path in processed_image_paths:\n",
        "                            logging.info(f\"Skipping already processed image: {output_image_path}\")\n",
        "                            continue\n",
        "\n",
        "\n",
        "                        command = (\n",
        "                            f'python run.py -s \"{source_image_path}\" -t \"{target_image_path}\" '\n",
        "                            f'-o \"{output_image_path}\" --keep-fps --execution-threads 14 --many-faces '\n",
        "                            f'--execution-provider cuda --frame-processor face_swapper face_enhancer '\n",
        "                            f'--output-video-quality 35 --temp-frame-format jpg --max-memory 46'\n",
        "                        )\n",
        "                        logging.info(f\"Running command: {command}\")\n",
        "\n",
        "                        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "                        stdout, stderr = process.communicate()\n",
        "                        if process.returncode != 0:\n",
        "                            logging.error(f\"Failed to process target image: {target_image_name}\")\n",
        "                            logging.error(f\"Command output: {stderr.decode('utf-8')}\")\n",
        "                        else:\n",
        "                            logging.info(f\"Successfully processed target image: {target_image_name}\")\n",
        "                            logging.info(f\"Command output: {stdout.decode('utf-8')}\")\n",
        "                            processed_image_paths.add(output_image_path)\n",
        "\n",
        "\n",
        "                        if len(processed_image_paths) >= len(template_images):\n",
        "                            break\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "\n",
        "@app.route('/faceswap', methods=['POST'])\n",
        "def faceswap_api():\n",
        "    try:\n",
        "\n",
        "        source_image_folder = \"/content/source_images\"\n",
        "        os.makedirs(source_image_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "        source_images = request.files.getlist('source_images')\n",
        "        if not source_images:\n",
        "            logging.error(\"No images uploaded.\")\n",
        "            return jsonify({\"error\": \"No images uploaded\"}), 400\n",
        "\n",
        "        for source_image in source_images:\n",
        "            source_image.save(os.path.join(source_image_folder, source_image.filename))\n",
        "            logging.info(f\"Uploaded image: {source_image.filename}\")\n",
        "\n",
        "        output_base_folder = \"/content\"\n",
        "\n",
        "        face_swap(source_image_folder, output_base_folder)\n",
        "\n",
        "\n",
        "        shutil.rmtree(source_image_folder)\n",
        "\n",
        "        return jsonify({\"message\": \"Face swap process initiated.\"}), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    url = ngrok.connect(5000)\n",
        "    print(f\" * Ngrok tunnel URL: {url}\")\n",
        "\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "id": "JArzYeREuyXU",
        "outputId": "7489d691-61e6-4c5d-c6cf-5a1d9f4f8ada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Ngrok tunnel URL: NgrokTunnel: \"https://e12b-35-240-203-31.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "ERROR:root:Failed to process target image: Navy Cap (3).png\n",
            "Downloading: 529MB [00:02, 190MB/s]                           \n",
            "Downloading: 332MB [00:04, 70.0MB/s]                          \n",
            "100%|██████████| 281857/281857 [00:03<00:00, 80275.17KB/s]\n",
            "Downloading...\n",
            "From: https://github.com/bhky/opennsfw2/releases/download/v0.1.0/open_nsfw_weights.h5\n",
            "To: /root/.opennsfw2/weights/open_nsfw_weights.h5\n",
            "100%|██████████| 24.2M/24.2M [00:00<00:00, 220MB/s]\n",
            "100%|██████████| 104M/104M [00:00<00:00, 312MB/s]\n",
            "100%|██████████| 81.4M/81.4M [00:00<00:00, 267MB/s]\n",
            "Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (1).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (26).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (19).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (17).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (27).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (21).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (23).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (14).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (24).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (20).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (22).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (18).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (25).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (3).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (1).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (26).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (19).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (17).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (27).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (21).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (23).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (14).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (24).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (20).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (22).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (18).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Navy Cap (25).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "INFO:werkzeug:127.0.0.1 - - [23/May/2024 11:14:21] \"POST /faceswap HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Connecting notebook to the Drive**"
      ],
      "metadata": {
        "id": "2xL9b7bIkPMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Sewb1tHMjkf5",
        "outputId": "abebe885-4c83-457c-a999-2e7b95f89982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **New JSON file for sample templates**"
      ],
      "metadata": {
        "id": "sHqa2MtoH5Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"categories\": {\n",
        "    \"Mall\": {\n",
        "      \"Male\": [\n",
        "        {\n",
        "          \"id\": \"1\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"2\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"3\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"4\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"5\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"6\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"7\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2\"\n",
        "        }\n",
        "      ],\n",
        "      \"Female\": [\n",
        "        {\n",
        "          \"id\": \"8\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"9\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"10\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"11\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"12\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"13\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"14\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"15\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"16\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"17\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"18\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"19\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"20\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    \"Nayagara\": {\n",
        "      \"Male\": [\n",
        "        {\n",
        "          \"id\": \"21\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"22\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"23\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"24\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"25\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"26\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"27\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"28\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-\"\n",
        "        }\n",
        "      ],\n",
        "      \"Female\": [\n",
        "        {\n",
        "          \"id\": \"29\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"30\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"31\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"32\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"33\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"34\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"35\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"36\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"37\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX\"\n",
        "        },\n",
        "        {\n",
        "          \"id\": \"38\",\n",
        "          \"url\": \"https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX\"\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "RWAwhaJNH4eA",
        "outputId": "71f7c401-1317-4018-ba18-7b28ddf16486",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': {'Mall': {'Male': [{'id': '1',\n",
              "     'url': 'https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2'},\n",
              "    {'id': '2',\n",
              "     'url': 'https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2'},\n",
              "    {'id': '3',\n",
              "     'url': 'https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2'},\n",
              "    {'id': '4',\n",
              "     'url': 'https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2'},\n",
              "    {'id': '5',\n",
              "     'url': 'https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2'},\n",
              "    {'id': '6',\n",
              "     'url': 'https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2'},\n",
              "    {'id': '7',\n",
              "     'url': 'https://drive.google.com/drive/folders/13BBrnYNBRBlybsemOi9WYTnm3zIEWLR2'}],\n",
              "   'Female': [{'id': '8',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '9',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '10',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '11',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '12',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '13',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '14',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '15',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '16',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '17',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '18',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '19',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'},\n",
              "    {'id': '20',\n",
              "     'url': 'https://drive.google.com/drive/folders/11Lg4gyOPV0om7isdbbnmvs9i5K_uTtGP'}]},\n",
              "  'Nayagara': {'Male': [{'id': '21',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-'},\n",
              "    {'id': '22',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-'},\n",
              "    {'id': '23',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-'},\n",
              "    {'id': '24',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-'},\n",
              "    {'id': '25',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-'},\n",
              "    {'id': '26',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-'},\n",
              "    {'id': '27',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-'},\n",
              "    {'id': '28',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-TYdIsNt_Hu-1cvIuk07QEBwM3JNr8H-'}],\n",
              "   'Female': [{'id': '29',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX'},\n",
              "    {'id': '30',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX'},\n",
              "    {'id': '31',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX'},\n",
              "    {'id': '32',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX'},\n",
              "    {'id': '33',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX'},\n",
              "    {'id': '34',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX'},\n",
              "    {'id': '35',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX'},\n",
              "    {'id': '36',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX'},\n",
              "    {'id': '37',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX'},\n",
              "    {'id': '38',\n",
              "     'url': 'https://drive.google.com/drive/folders/1-bdRq16dLMxSOmqdlpXLvyGp6oZ7hBMX'}]}}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the json file for template API**"
      ],
      "metadata": {
        "id": "9YPVugoYL3fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"categories\": {\n",
        "    \"category1\": [\n",
        "      \"https://drive.google.com/uc?id=1-T922LMrBkHBQL9OuM8ZMWcW91k19oot\",\n",
        "      \"https://drive.google.com/uc?id=1-NTz8uGFjXHOfweygfbZI3UaZ7sBGvtt\",\n",
        "      \"https://drive.google.com/uc?id=1-EVrOQOBrrH4cIndzFjGQr58gyPBe1Sh\",\n",
        "      \"https://drive.google.com/uc?id=1-Ch2-ANY3_r72jwQ63macpj-Ju-HsmVl\",\n",
        "      \"https://drive.google.com/uc?id=1-Ay6QO8Bt2Lr97F8jscb22DiQ-MRhNe9\",\n",
        "      \"https://drive.google.com/uc?id=1-ADxhsyYbYtfjsuFtHOJlUM52FlkKTDi\"\n",
        "    ],\n",
        "    \"category2\": [\n",
        "      \"https://drive.google.com/uc?id=10HQHbfjV_33xa7WhZeYS4DMuQBqNpw3s\",\n",
        "      \"https://drive.google.com/uc?id=109B1r5auRVDKuUJhzn0TrLHhbQf7depB\",\n",
        "      \"https://drive.google.com/uc?id=1-sZ8lV6OGo4p1Kp7PPah58cZB0KfOiJ1\",\n",
        "      \"https://drive.google.com/uc?id=1-sJ-qYh9gAYHrbujcdBUaKOadLUuFtjj\",\n",
        "      \"https://drive.google.com/uc?id=1-poq_gCGlIWoTKRQFXgCGs1t_IAjPH2l\",\n",
        "      \"https://drive.google.com/uc?id=1-lmK7Fq_7UpqP_a1gP969MFgggfebKwI\",\n",
        "      \"https://drive.google.com/uc?id=1-gNkqHvt_wHnQyTskO-SIdxhlB_vDH_o\",\n",
        "      \"https://drive.google.com/uc?id=1-ePjWcUSawXII4El6iiI27p05dZkUjgm\",\n",
        "      \"https://drive.google.com/uc?id=10Zu6mPX9G50Bi89CkzBTgaIIOe9jPQaP\",\n",
        "      \"https://drive.google.com/uc?id=10S62IrVbLyIa7rDlm0v6bL4hw88iCay-\",\n",
        "      \"https://drive.google.com/uc?id=10RazuWfDgbAjUQ8e7LnQhqjvZEzwNWfA\",\n",
        "      \"https://drive.google.com/uc?id=10M_UvI7fhyOSz4JuHyrdRx1r2QePNCki\",\n",
        "      \"https://drive.google.com/uc?id=10LGIUYQptd6O91ld2KaCw52LdT9VVgf5\"\n",
        "    ]\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "ypEvxcS9Pbhy",
        "outputId": "7f0946f9-baaf-48a8-e36e-5fbeca4d7d2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': {'category1': ['https://drive.google.com/uc?id=1-T922LMrBkHBQL9OuM8ZMWcW91k19oot',\n",
              "   'https://drive.google.com/uc?id=1-NTz8uGFjXHOfweygfbZI3UaZ7sBGvtt',\n",
              "   'https://drive.google.com/uc?id=1-EVrOQOBrrH4cIndzFjGQr58gyPBe1Sh',\n",
              "   'https://drive.google.com/uc?id=1-Ch2-ANY3_r72jwQ63macpj-Ju-HsmVl',\n",
              "   'https://drive.google.com/uc?id=1-Ay6QO8Bt2Lr97F8jscb22DiQ-MRhNe9',\n",
              "   'https://drive.google.com/uc?id=1-ADxhsyYbYtfjsuFtHOJlUM52FlkKTDi'],\n",
              "  'category2': ['https://drive.google.com/uc?id=10HQHbfjV_33xa7WhZeYS4DMuQBqNpw3s',\n",
              "   'https://drive.google.com/uc?id=109B1r5auRVDKuUJhzn0TrLHhbQf7depB',\n",
              "   'https://drive.google.com/uc?id=1-sZ8lV6OGo4p1Kp7PPah58cZB0KfOiJ1',\n",
              "   'https://drive.google.com/uc?id=1-sJ-qYh9gAYHrbujcdBUaKOadLUuFtjj',\n",
              "   'https://drive.google.com/uc?id=1-poq_gCGlIWoTKRQFXgCGs1t_IAjPH2l',\n",
              "   'https://drive.google.com/uc?id=1-lmK7Fq_7UpqP_a1gP969MFgggfebKwI',\n",
              "   'https://drive.google.com/uc?id=1-gNkqHvt_wHnQyTskO-SIdxhlB_vDH_o',\n",
              "   'https://drive.google.com/uc?id=1-ePjWcUSawXII4El6iiI27p05dZkUjgm',\n",
              "   'https://drive.google.com/uc?id=10Zu6mPX9G50Bi89CkzBTgaIIOe9jPQaP',\n",
              "   'https://drive.google.com/uc?id=10S62IrVbLyIa7rDlm0v6bL4hw88iCay-',\n",
              "   'https://drive.google.com/uc?id=10RazuWfDgbAjUQ8e7LnQhqjvZEzwNWfA',\n",
              "   'https://drive.google.com/uc?id=10M_UvI7fhyOSz4JuHyrdRx1r2QePNCki',\n",
              "   'https://drive.google.com/uc?id=10LGIUYQptd6O91ld2KaCw52LdT9VVgf5']}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **creating your Flask app to serve the JSON data**"
      ],
      "metadata": {
        "id": "w5INxbwrwGKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-ngrok"
      ],
      "metadata": {
        "id": "V8pgIylQxieN",
        "outputId": "c36c8f1a-98c5-4957-a139-bf4a14b82703",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "\n",
        "json_path = '/content/drive/MyDrive/templates/categories.json'\n",
        "with open(json_path) as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "@app.route('/categories', methods=['GET'])\n",
        "def get_categories():\n",
        "    return jsonify(data)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        app.run()\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "\n",
        "        time.sleep(5)\n",
        "        app.run()\n"
      ],
      "metadata": {
        "id": "j-_zkBVuz68V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify\n",
        "import json\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when the app is run\n",
        "\n",
        "# Load your JSON data\n",
        "json_path = '/content/drive/MyDrive/templates/categories.json'\n",
        "with open(json_path) as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "@app.route('/categories', methods=['GET'])\n",
        "def get_categories():\n",
        "    return jsonify(data)\n",
        "\n",
        "@app.route('/categories/<category_id>', methods=['GET'])\n",
        "def get_category_by_id(category_id):\n",
        "    category = data['categories'].get(category_id)\n",
        "    if category:\n",
        "        return jsonify(category)\n",
        "    else:\n",
        "        return jsonify({'error': 'Category not found'}), 404\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "id": "X575lRt6WB5Y",
        "outputId": "55080f17-28e3-4698-93aa-5098a3717513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://c7df-35-230-47-52.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [24/May/2024 11:30:49] \"\u001b[33mGET /categories/8 HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/May/2024 11:32:04] \"GET /categories HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/May/2024 11:33:10] \"GET /categories/Nayagara HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Added API to display output images**"
      ],
      "metadata": {
        "id": "lYHDGRklWIBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, send_from_directory\n",
        "import os\n",
        "import shutil\n",
        "import logging\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "TEMPLATES_FOLDER_PATH = \"/content/drive/MyDrive/templates/florist\"\n",
        "OUTPUT_BASE_FOLDER = \"/content/drive/MyDrive\"\n",
        "\n",
        "def face_swap(source_image_folder, output_base_folder):\n",
        "    try:\n",
        "        output_folder = os.path.join(output_base_folder, \"RG(Outputs)\")\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        logging.info(f\"Output folder created at: {output_folder}\")\n",
        "\n",
        "        source_images = os.listdir(source_image_folder)\n",
        "        if not source_images:\n",
        "            logging.error(\"No source images found.\")\n",
        "            return\n",
        "        logging.info(f\"Found {len(source_images)} source images.\")\n",
        "\n",
        "        template_images = os.listdir(TEMPLATES_FOLDER_PATH)\n",
        "        if not template_images:\n",
        "            logging.error(\"No template images found.\")\n",
        "            return\n",
        "        logging.info(f\"Found {len(template_images)} template images.\")\n",
        "\n",
        "\n",
        "        source_image_name = source_images[0]\n",
        "        source_image_path = os.path.join(source_image_folder, source_image_name)\n",
        "\n",
        "        if os.path.isfile(source_image_path):\n",
        "            logging.info(f\"Processing source image: {source_image_name}\")\n",
        "\n",
        "            processed_image_paths = set()\n",
        "\n",
        "            for target_image_name in template_images:\n",
        "                target_image_path = os.path.join(TEMPLATES_FOLDER_PATH, target_image_name)\n",
        "\n",
        "                if os.path.isfile(target_image_path):\n",
        "                    logging.info(f\"Processing target image: {target_image_name}\")\n",
        "\n",
        "                    output_image_path = os.path.join(output_folder, f\"{source_image_name}_{target_image_name}\")\n",
        "                    if output_image_path in processed_image_paths:\n",
        "                        logging.info(f\"Skipping already processed image: {output_image_path}\")\n",
        "                        continue\n",
        "\n",
        "                    command = (\n",
        "                        f'python run.py -s \"{source_image_path}\" -t \"{target_image_path}\" '\n",
        "                        f'-o \"{output_image_path}\" --keep-fps --execution-threads 14 --many-faces '\n",
        "                        f'--execution-provider cuda --frame-processor face_swapper face_enhancer '\n",
        "                        f'--output-video-quality 35 --temp-frame-format jpg --max-memory 46'\n",
        "                    )\n",
        "                    logging.info(f\"Running command: {command}\")\n",
        "\n",
        "                    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "                    stdout, stderr = process.communicate()\n",
        "                    if process.returncode != 0:\n",
        "                        logging.error(f\"Failed to process target image: {target_image_name}\")\n",
        "                        logging.error(f\"Command output: {stderr.decode('utf-8')}\")\n",
        "                    else:\n",
        "                        logging.info(f\"Successfully processed target image: {target_image_name}\")\n",
        "                        logging.info(f\"Command output: {stdout.decode('utf-8')}\")\n",
        "                        processed_image_paths.add(output_image_path)\n",
        "\n",
        "                    if len(processed_image_paths) >= len(template_images):\n",
        "                        break\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "\n",
        "@app.route('/faceswap', methods=['POST'])\n",
        "def faceswap_api():\n",
        "    try:\n",
        "        source_image_folder = \"/content/source_images\"\n",
        "        os.makedirs(source_image_folder, exist_ok=True)\n",
        "\n",
        "        source_images = request.files.getlist('source_images')\n",
        "        if not source_images:\n",
        "            logging.error(\"No images uploaded.\")\n",
        "            return jsonify({\"error\": \"No images uploaded\"}), 400\n",
        "\n",
        "        for source_image in source_images:\n",
        "            source_image.save(os.path.join(source_image_folder, source_image.filename))\n",
        "            logging.info(f\"Uploaded image: {source_image.filename}\")\n",
        "\n",
        "        face_swap(source_image_folder, OUTPUT_BASE_FOLDER)\n",
        "\n",
        "        shutil.rmtree(source_image_folder)\n",
        "\n",
        "        return jsonify({\"message\": \"Face swap process initiated.\"}), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "@app.route('/output_images', methods=['GET'])\n",
        "def output_images_api():\n",
        "    try:\n",
        "        output_folder = os.path.join(OUTPUT_BASE_FOLDER, \"(Outputs)\")\n",
        "        if not os.path.exists(output_folder):\n",
        "            logging.error(\"Output folder does not exist.\")\n",
        "            return jsonify({\"error\": \"Output folder does not exist\"}), 404\n",
        "\n",
        "        output_images = os.listdir(output_folder)\n",
        "        if not output_images:\n",
        "            logging.info(\"No output images found.\")\n",
        "            return jsonify({\"message\": \"No output images found.\"}), 200\n",
        "\n",
        "        return jsonify({\"output_images\": output_images}), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "@app.route('/output_images/<filename>', methods=['GET'])\n",
        "def get_output_image(filename):\n",
        "    try:\n",
        "        output_folder = os.path.join(OUTPUT_BASE_FOLDER, \"(Outputs)\")\n",
        "        return send_from_directory(output_folder, filename)\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    url = ngrok.connect(5000)\n",
        "    print(f\" * Ngrok tunnel URL: {url}\")\n",
        "\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "id": "cmEI_j80WHGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **changes the output to be displayed in Zipfile**"
      ],
      "metadata": {
        "id": "GyqiPLAZS8Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, send_from_directory, send_file\n",
        "import os\n",
        "import shutil\n",
        "import logging\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "TEMPLATES_FOLDER_PATH = \"/content/drive/MyDrive/template/doctor/Female\"\n",
        "OUTPUT_BASE_FOLDER = \"/content/drive/MyDrive\"\n",
        "\n",
        "def face_swap(source_image_folder, output_base_folder):\n",
        "    try:\n",
        "        output_folder = os.path.join(output_base_folder, \"(Outputs)\")\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        logging.info(f\"Output folder created at: {output_folder}\")\n",
        "\n",
        "        source_images = os.listdir(source_image_folder)\n",
        "        if not source_images:\n",
        "            logging.error(\"No source images found.\")\n",
        "            return\n",
        "        logging.info(f\"Found {len(source_images)} source images.\")\n",
        "\n",
        "        template_images = os.listdir(TEMPLATES_FOLDER_PATH)\n",
        "        if not template_images:\n",
        "            logging.error(\"No template images found.\")\n",
        "            return\n",
        "        logging.info(f\"Found {len(template_images)} template images.\")\n",
        "\n",
        "        source_image_name = source_images[0]\n",
        "        source_image_path = os.path.join(source_image_folder, source_image_name)\n",
        "\n",
        "        if os.path.isfile(source_image_path):\n",
        "            logging.info(f\"Processing source image: {source_image_name}\")\n",
        "\n",
        "            processed_image_paths = set()\n",
        "\n",
        "            for target_image_name in template_images:\n",
        "                target_image_path = os.path.join(TEMPLATES_FOLDER_PATH, target_image_name)\n",
        "\n",
        "                if os.path.isfile(target_image_path):\n",
        "                    logging.info(f\"Processing target image: {target_image_name}\")\n",
        "\n",
        "                    output_image_path = os.path.join(output_folder, f\"{source_image_name}_{target_image_name}\")\n",
        "                    if output_image_path in processed_image_paths:\n",
        "                        logging.info(f\"Skipping already processed image: {output_image_path}\")\n",
        "                        continue\n",
        "\n",
        "                    command = (\n",
        "                        f'python run.py -s \"{source_image_path}\" -t \"{target_image_path}\" '\n",
        "                        f'-o \"{output_image_path}\" --keep-fps --execution-threads 14 --many-faces '\n",
        "                        f'--execution-provider cuda --frame-processor face_swapper face_enhancer '\n",
        "                        f'--output-video-quality 35 --temp-frame-format jpg --max-memory 46'\n",
        "                    )\n",
        "                    logging.info(f\"Running command: {command}\")\n",
        "\n",
        "                    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "                    stdout, stderr = process.communicate()\n",
        "                    if process.returncode != 0:\n",
        "                        logging.error(f\"Failed to process target image: {target_image_name}\")\n",
        "                        logging.error(f\"Command output: {stderr.decode('utf-8')}\")\n",
        "                    else:\n",
        "                        logging.info(f\"Successfully processed target image: {target_image_name}\")\n",
        "                        logging.info(f\"Command output: {stdout.decode('utf-8')}\")\n",
        "                        processed_image_paths.add(output_image_path)\n",
        "\n",
        "                    if len(processed_image_paths) >= len(template_images):\n",
        "                        break\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "\n",
        "@app.route('/faceswap', methods=['POST'])\n",
        "def faceswap_api():\n",
        "    try:\n",
        "        source_image_folder = \"/content/source_images\"\n",
        "        os.makedirs(source_image_folder, exist_ok=True)\n",
        "\n",
        "        source_images = request.files.getlist('source_images')\n",
        "        if not source_images:\n",
        "            logging.error(\"No images uploaded.\")\n",
        "            return jsonify({\"error\": \"No images uploaded\"}), 400\n",
        "\n",
        "        for source_image in source_images:\n",
        "            source_image.save(os.path.join(source_image_folder, source_image.filename))\n",
        "            logging.info(f\"Uploaded image: {source_image.filename}\")\n",
        "\n",
        "        face_swap(source_image_folder, OUTPUT_BASE_FOLDER)\n",
        "\n",
        "        shutil.rmtree(source_image_folder)\n",
        "\n",
        "        return jsonify({\"message\": \"Face swap process initiated.\"}), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "@app.route('/output_images', methods=['GET'])\n",
        "def output_images_api():\n",
        "    try:\n",
        "        output_folder = os.path.join(OUTPUT_BASE_FOLDER, \"(Outputs)\")\n",
        "        if not os.path.exists(output_folder):\n",
        "            logging.error(\"Output folder does not exist.\")\n",
        "            return jsonify({\"error\": \"Output folder does not exist\"}), 404\n",
        "\n",
        "        output_images = os.listdir(output_folder)\n",
        "        if not output_images:\n",
        "            logging.info(\"No output images found.\")\n",
        "            return jsonify({\"message\": \"No output images found.\"}), 200\n",
        "\n",
        "        # Create a zip file in memory\n",
        "        memory_file = io.BytesIO()\n",
        "        with zipfile.ZipFile(memory_file, 'w') as zf:\n",
        "            for filename in output_images:\n",
        "                filepath = os.path.join(output_folder, filename)\n",
        "                zf.write(filepath, filename)\n",
        "        memory_file.seek(0)\n",
        "\n",
        "        return send_file(memory_file, attachment_filename='output_images.zip', as_attachment=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "@app.route('/output_images/<filename>', methods=['GET'])\n",
        "def get_output_image(filename):\n",
        "    try:\n",
        "        output_folder = os.path.join(OUTPUT_BASE_FOLDER, \"(Outputs)\")\n",
        "        return send_from_directory(output_folder, filename)\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    url = ngrok.connect(5000)\n",
        "    print(f\" * Ngrok tunnel URL: {url}\")\n",
        "\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "id": "Zdr2kx-pPBgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This code working as expected**"
      ],
      "metadata": {
        "id": "aBt1Rg5xSsVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, send_from_directory, send_file\n",
        "import os\n",
        "import shutil\n",
        "import logging\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "TEMPLATES_FOLDER_PATH = \"/content/drive/MyDrive/templates/florist\"\n",
        "OUTPUT_BASE_FOLDER = \"/content/drive/MyDrive/(Outputs)\"\n",
        "\n",
        "def face_swap(source_image_folder, output_base_folder):\n",
        "    try:\n",
        "        output_folder = os.path.join(output_base_folder, \"RG(Outputs)\")\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        logging.info(f\"Output folder created at: {output_folder}\")\n",
        "\n",
        "        source_images = os.listdir(source_image_folder)\n",
        "        if not source_images:\n",
        "            logging.error(\"No source images found.\")\n",
        "            return\n",
        "        logging.info(f\"Found {len(source_images)} source images.\")\n",
        "\n",
        "        template_images = os.listdir(TEMPLATES_FOLDER_PATH)\n",
        "        if not template_images:\n",
        "            logging.error(\"No template images found.\")\n",
        "            return\n",
        "        logging.info(f\"Found {len(template_images)} template images.\")\n",
        "\n",
        "        source_image_name = source_images[0]\n",
        "        source_image_path = os.path.join(source_image_folder, source_image_name)\n",
        "\n",
        "        if os.path.isfile(source_image_path):\n",
        "            logging.info(f\"Processing source image: {source_image_name}\")\n",
        "\n",
        "            processed_image_paths = set()\n",
        "\n",
        "            for target_image_name in template_images:\n",
        "                target_image_path = os.path.join(TEMPLATES_FOLDER_PATH, target_image_name)\n",
        "\n",
        "                if os.path.isfile(target_image_path):\n",
        "                    logging.info(f\"Processing target image: {target_image_name}\")\n",
        "\n",
        "                    output_image_path = os.path.join(output_folder, f\"{source_image_name}_{target_image_name}\")\n",
        "                    if output_image_path in processed_image_paths:\n",
        "                        logging.info(f\"Skipping already processed image: {output_image_path}\")\n",
        "                        continue\n",
        "\n",
        "                    command = (\n",
        "                        f'python run.py -s \"{source_image_path}\" -t \"{target_image_path}\" '\n",
        "                        f'-o \"{output_image_path}\" --keep-fps --execution-threads 14 --many-faces '\n",
        "                        f'--execution-provider cuda --frame-processor face_swapper face_enhancer '\n",
        "                        f'--output-video-quality 35 --temp-frame-format jpg --max-memory 46'\n",
        "                    )\n",
        "                    logging.info(f\"Running command: {command}\")\n",
        "\n",
        "                    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "                    stdout, stderr = process.communicate()\n",
        "                    if process.returncode != 0:\n",
        "                        logging.error(f\"Failed to process target image: {target_image_name}\")\n",
        "                        logging.error(f\"Command output: {stderr.decode('utf-8')}\")\n",
        "                    else:\n",
        "                        logging.info(f\"Successfully processed target image: {target_image_name}\")\n",
        "                        logging.info(f\"Command output: {stdout.decode('utf-8')}\")\n",
        "                        processed_image_paths.add(output_image_path)\n",
        "\n",
        "                    if len(processed_image_paths) >= len(template_images):\n",
        "                        break\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "\n",
        "@app.route('/faceswap', methods=['POST'])\n",
        "def faceswap_api():\n",
        "    try:\n",
        "        source_image_folder = \"/content/source_images\"\n",
        "        os.makedirs(source_image_folder, exist_ok=True)\n",
        "\n",
        "        source_images = request.files.getlist('source_images')\n",
        "        if not source_images:\n",
        "            logging.error(\"No images uploaded.\")\n",
        "            return jsonify({\"error\": \"No images uploaded\"}), 400\n",
        "\n",
        "        for source_image in source_images:\n",
        "            source_image.save(os.path.join(source_image_folder, source_image.filename))\n",
        "            logging.info(f\"Uploaded image: {source_image.filename}\")\n",
        "\n",
        "        face_swap(source_image_folder, OUTPUT_BASE_FOLDER)\n",
        "\n",
        "        shutil.rmtree(source_image_folder)\n",
        "\n",
        "        return jsonify({\"message\": \"Face swap process initiated.\"}), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "@app.route('/output_images', methods=['GET'])\n",
        "def output_images_api():\n",
        "    try:\n",
        "        output_folder = os.path.join(OUTPUT_BASE_FOLDER, \"RG(Outputs)\")\n",
        "        if not os.path.exists(output_folder):\n",
        "            logging.error(\"Output folder does not exist.\")\n",
        "            return jsonify({\"error\": \"Output folder does not exist\"}), 404\n",
        "\n",
        "        output_images = os.listdir(output_folder)\n",
        "        if not output_images:\n",
        "            logging.info(\"No output images found.\")\n",
        "            return jsonify({\"message\": \"No output images found.\"}), 200\n",
        "\n",
        "\n",
        "        memory_file = io.BytesIO()\n",
        "        with zipfile.ZipFile(memory_file, 'w') as zf:\n",
        "            for filename in output_images:\n",
        "                filepath = os.path.join(output_folder, filename)\n",
        "                zf.write(filepath, filename)\n",
        "        memory_file.seek(0)\n",
        "\n",
        "        return send_file(memory_file, download_name='output_images.zip', as_attachment=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "@app.route('/output_images/<filename>', methods=['GET'])\n",
        "def get_output_image(filename):\n",
        "    try:\n",
        "        output_folder = os.path.join(OUTPUT_BASE_FOLDER, \"RG(Outputs)\")\n",
        "        return send_from_directory(output_folder, filename)\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    url = ngrok.connect(5000)\n",
        "    print(f\" * Ngrok tunnel URL: {url}\")\n",
        "\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "id": "2bGjdWMESr0Z",
        "outputId": "bc094812-ebd5-4cf6-ec21-44e9a6b8d85b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Ngrok tunnel URL: NgrokTunnel: \"https://0089-34-127-105-7.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "ERROR:root:Failed to process target image: Florist (12).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (13).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (14).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (15).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (16).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (17).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (18).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (1).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (2).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (4).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (10).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (3).png\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "INFO:werkzeug:127.0.0.1 - - [27/May/2024 06:20:32] \"POST /faceswap HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trying to store the output images file as temprary file**"
      ],
      "metadata": {
        "id": "8C7q3vM0aBzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, send_from_directory, send_file\n",
        "import os\n",
        "import shutil\n",
        "import logging\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import zipfile\n",
        "import io\n",
        "import tempfile\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "TEMPLATES_FOLDER_PATH = \"/content/drive/MyDrive/templates/florist\"\n",
        "\n",
        "def face_swap(source_image_folder, temp_output_folder):\n",
        "    try:\n",
        "        output_folder = os.path.join(temp_output_folder, \"RG(Outputs)\")\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        logging.info(f\"Output folder created at: {output_folder}\")\n",
        "\n",
        "        source_images = os.listdir(source_image_folder)\n",
        "        if not source_images:\n",
        "            logging.error(\"No source images found.\")\n",
        "            return\n",
        "        logging.info(f\"Found {len(source_images)} source images.\")\n",
        "\n",
        "        template_images = os.listdir(TEMPLATES_FOLDER_PATH)\n",
        "        if not template_images:\n",
        "            logging.error(\"No template images found.\")\n",
        "            return\n",
        "        logging.info(f\"Found {len(template_images)} template images.\")\n",
        "\n",
        "        source_image_name = source_images[0]\n",
        "        source_image_path = os.path.join(source_image_folder, source_image_name)\n",
        "\n",
        "        if os.path.isfile(source_image_path):\n",
        "            logging.info(f\"Processing source image: {source_image_name}\")\n",
        "\n",
        "            processed_image_paths = set()\n",
        "\n",
        "            for target_image_name in template_images:\n",
        "                target_image_path = os.path.join(TEMPLATES_FOLDER_PATH, target_image_name)\n",
        "\n",
        "                if os.path.isfile(target_image_path):\n",
        "                    logging.info(f\"Processing target image: {target_image_name}\")\n",
        "\n",
        "                    output_image_path = os.path.join(output_folder, f\"{source_image_name}_{target_image_name}\")\n",
        "                    if output_image_path in processed_image_paths:\n",
        "                        logging.info(f\"Skipping already processed image: {output_image_path}\")\n",
        "                        continue\n",
        "\n",
        "                    command = (\n",
        "                        f'python run.py -s \"{source_image_path}\" -t \"{target_image_path}\" '\n",
        "                        f'-o \"{output_image_path}\" --keep-fps --execution-threads 14 --many-faces '\n",
        "                        f'--execution-provider cuda --frame-processor face_swapper face_enhancer '\n",
        "                        f'--output-video-quality 35 --temp-frame-format jpg --max-memory 46'\n",
        "                    )\n",
        "                    logging.info(f\"Running command: {command}\")\n",
        "\n",
        "                    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "                    stdout, stderr = process.communicate()\n",
        "                    if process.returncode != 0:\n",
        "                        logging.error(f\"Failed to process target image: {target_image_name}\")\n",
        "                        logging.error(f\"Command output: {stderr.decode('utf-8')}\")\n",
        "                    else:\n",
        "                        logging.info(f\"Successfully processed target image: {target_image_name}\")\n",
        "                        logging.info(f\"Command output: {stdout.decode('utf-8')}\")\n",
        "                        processed_image_paths.add(output_image_path)\n",
        "\n",
        "                    if len(processed_image_paths) >= len(template_images):\n",
        "                        break\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "\n",
        "@app.route('/faceswap', methods=['POST'])\n",
        "def faceswap_api():\n",
        "    try:\n",
        "        source_image_folder = tempfile.mkdtemp()\n",
        "        logging.info(f\"Temporary source image folder created at: {source_image_folder}\")\n",
        "\n",
        "        source_images = request.files.getlist('source_images')\n",
        "        if not source_images:\n",
        "            logging.error(\"No images uploaded.\")\n",
        "            return jsonify({\"error\": \"No images uploaded\"}), 400\n",
        "\n",
        "        for source_image in source_images:\n",
        "            source_image.save(os.path.join(source_image_folder, source_image.filename))\n",
        "            logging.info(f\"Uploaded image: {source_image.filename}\")\n",
        "\n",
        "        temp_output_folder = tempfile.mkdtemp()\n",
        "        logging.info(f\"Temporary output folder created at: {temp_output_folder}\")\n",
        "\n",
        "        face_swap(source_image_folder, temp_output_folder)\n",
        "\n",
        "        shutil.rmtree(source_image_folder)\n",
        "\n",
        "        return jsonify({\"message\": \"Face swap process initiated.\", \"output_folder\": temp_output_folder}), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "@app.route('/output_images', methods=['GET'])\n",
        "def output_images_api():\n",
        "    try:\n",
        "        temp_output_folder = request.args.get('temp_output_folder')\n",
        "        if not temp_output_folder or not os.path.exists(temp_output_folder):\n",
        "            logging.error(\"Output folder does not exist.\")\n",
        "            return jsonify({\"error\": \"Output folder does not exist\"}), 404\n",
        "\n",
        "        output_folder = os.path.join(temp_output_folder, \"(Outputs)\")\n",
        "        output_images = os.listdir(output_folder)\n",
        "        if not output_images:\n",
        "            logging.info(\"No output images found.\")\n",
        "            return jsonify({\"message\": \"No output images found.\"}), 200\n",
        "\n",
        "        # Create a zip file in memory\n",
        "        memory_file = io.BytesIO()\n",
        "        with zipfile.ZipFile(memory_file, 'w') as zf:\n",
        "            for filename in output_images:\n",
        "                filepath = os.path.join(output_folder, filename)\n",
        "                zf.write(filepath, filename)\n",
        "        memory_file.seek(0)\n",
        "\n",
        "        shutil.rmtree(temp_output_folder)  # Clean up the temporary output folder\n",
        "\n",
        "        return send_file(memory_file, download_name='output_images.zip', as_attachment=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "@app.route('/output_images/<filename>', methods=['GET'])\n",
        "def get_output_image(filename):\n",
        "    try:\n",
        "        temp_output_folder = request.args.get('temp_output_folder')\n",
        "        if not temp_output_folder or not os.path.exists(temp_output_folder):\n",
        "            logging.error(\"Output folder does not exist.\")\n",
        "            return jsonify({\"error\": \"Output folder does not exist\"}), 404\n",
        "\n",
        "        output_folder = os.path.join(temp_output_folder, \"(Outputs)\")\n",
        "        return send_from_directory(output_folder, filename)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")\n",
        "        return jsonify({\"error\": \"An error occurred\"}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    url = ngrok.connect(5000)\n",
        "    print(f\" * Ngrok tunnel URL: {url}\")\n",
        "\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "id": "LlHiLvFcaMtz",
        "outputId": "a3cf5456-9f7e-43a1-bc98-c1f9addd13af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Ngrok tunnel URL: NgrokTunnel: \"https://0a1f-34-127-105-7.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "ERROR:root:Failed to process target image: Florist (12).jpg\n",
            "Downloading: 529MB [00:03, 181MB/s]                           \n",
            "Downloading: 332MB [00:01, 211MB/s]                           \n",
            "100%|██████████| 281857/281857 [00:05<00:00, 54975.53KB/s]\n",
            "Downloading...\n",
            "From: https://github.com/bhky/opennsfw2/releases/download/v0.1.0/open_nsfw_weights.h5\n",
            "To: /root/.opennsfw2/weights/open_nsfw_weights.h5\n",
            "100%|██████████| 24.2M/24.2M [00:00<00:00, 45.2MB/s]\n",
            "100%|██████████| 104M/104M [00:00<00:00, 206MB/s] \n",
            "100%|██████████| 81.4M/81.4M [00:00<00:00, 176MB/s]\n",
            "Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (13).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (14).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (15).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (16).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (17).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "ERROR:root:Failed to process target image: Florist (18).jpg\n",
            "ERROR:root:Command output: Segmentation fault (core dumped)\n",
            "\n",
            "INFO:werkzeug:127.0.0.1 - - [27/May/2024 05:25:48] \"POST /faceswap HTTP/1.1\" 200 -\n",
            "ERROR:root:Output folder does not exist.\n",
            "INFO:werkzeug:127.0.0.1 - - [27/May/2024 05:28:34] \"\u001b[33mGET /output_images HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bbUbcyJsuoL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}