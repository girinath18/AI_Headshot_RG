{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girinath18/AI_Headshot_RG/blob/main/Nokia2Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/girinath18/roop.git\n",
        "%cd roop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lDysP3tdL7r",
        "outputId": "4726101c-f9fb-49e3-f2e2-8db178d14086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'roop'...\n",
            "remote: Enumerating objects: 1540, done.\u001b[K\n",
            "remote: Total 1540 (delta 0), reused 0 (delta 0), pack-reused 1540\u001b[K\n",
            "Receiving objects: 100% (1540/1540), 97.43 MiB | 41.48 MiB/s, done.\n",
            "Resolving deltas: 100% (917/917), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd roop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2geXbz3c9MM",
        "outputId": "bbfdc681-da54-4528-e52e-551750486377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/roop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from google.colab import files\n",
        "\n",
        "uploadimg = files.upload()\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o_GT1EXcWCN0",
        "outputId": "8d712d3f-9b3c-4daf-ec17-efbbca832a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom google.colab import files\\n\\nuploadimg = files.upload()\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n",
        "!pip install customtkinter\n",
        "!pip install -r /content/roop/requirements.txt\n",
        "!pip install -r /content/Face_Swap/requirements.txt\n",
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkAhFhQ3d2vr",
        "outputId": "1ab29a70-35b2-4200-ed12-e076a8333ccd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.3\n",
            "Collecting customtkinter\n",
            "  Downloading customtkinter-5.2.2-py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting darkdetect (from customtkinter)\n",
            "  Downloading darkdetect-0.8.0-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from customtkinter) (24.0)\n",
            "Installing collected packages: darkdetect, customtkinter\n",
            "Successfully installed customtkinter-5.2.2 darkdetect-0.8.0\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '/content/roop/requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '/content/Face_Swap/requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Single Source image Single target image**"
      ],
      "metadata": {
        "id": "AWSpJMqjXaMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "\n",
        "source_image_path = input(\"Enter the path to the source image: \")\n",
        "\n",
        "target_image_path = input(\"Enter the path to the target image: \")\n",
        "\n",
        "output_folder = \"/content/RG(Outputs)/\"\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "!python /content/roop/run.py -s \"{source_image_path}\" -t \"{target_image_path}\" -o \"{output_folder}\" --keep-fps --execution-threads 14 --many-faces --execution-provider cuda --frame-processor face_swapper face_enhancer --output-video-quality 35 --temp-frame-format jpg --max-memory 46\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "J8GgUAZYka0U",
        "outputId": "65afe60b-5582-4e0e-aea0-270ea4ccd686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\n\\nsource_image_path = input(\"Enter the path to the source image: \")\\n\\ntarget_image_path = input(\"Enter the path to the target image: \")\\n\\noutput_folder = \"/content/RG(Outputs)/\"\\n\\nos.makedirs(output_folder, exist_ok=True)\\n\\n!python /content/roop/run.py -s \"{source_image_path}\" -t \"{target_image_path}\" -o \"{output_folder}\" --keep-fps --execution-threads 14 --many-faces --execution-provider cuda --frame-processor face_swapper face_enhancer --output-video-quality 35 --temp-frame-format jpg --max-memory 46\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Single Source Image** X **Folder Target Images**"
      ],
      "metadata": {
        "id": "mJldgOvXXvKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "\n",
        "source_image_path = input(\"Enter the path to the source image: \")\n",
        "templates_folder_path = input(\"Enter the path to the templates folder: \")\n",
        "\n",
        "output_folder = \"/content/RG(Outputs)/\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "for target_image_name in os.listdir(templates_folder_path):\n",
        "    target_image_path = os.path.join(templates_folder_path, target_image_name)\n",
        "\n",
        "\n",
        "    if os.path.isfile(target_image_path):\n",
        "        print(\"Processing target image:\", target_image_name)\n",
        "\n",
        "\n",
        "        !python /content/roop/run.py -s \"{source_image_path}\" -t \"{target_image_path}\" -o \"{output_folder}\" --keep-fps --execution-threads 14 --many-faces --execution-provider cuda --frame-processor face_swapper face_enhancer --output-video-quality 35 --temp-frame-format jpg --max-memory 46\n",
        "'''"
      ],
      "metadata": {
        "id": "-cu36C683at7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "import random\n",
        "\n",
        "source_image_folder = input(\"Enter the path to the folder containing source images: \")\n",
        "templates_folder_path = input(\"Enter the path to the templates folder: \")\n",
        "\n",
        "output_folder = \"/content/RGR(Outputs)/\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Get list of source image filenames\n",
        "source_images = os.listdir(source_image_folder)\n",
        "\n",
        "#Randomly select one source image\n",
        "selected_source_image = random.choice(source_images)\n",
        "selected_source_image_path = os.path.join(source_image_folder, selected_source_image)\n",
        "\n",
        "#Iterate over target images in the templates folder\n",
        "for target_image_name in os.listdir(templates_folder_path):\n",
        "    target_image_path = os.path.join(templates_folder_path, target_image_name)\n",
        "\n",
        "    #Check if the item in the folder is a file\n",
        "    if os.path.isfile(target_image_path):\n",
        "        print(\"Processing target image:\", target_image_name)\n",
        "\n",
        "        #Run the command for each target image\n",
        "        os.system(f'python /content/roop/run.py -s \"{selected_source_image_path}\" -t \"{target_image_path}\" -o \"{output_folder}\" --keep-fps --execution-threads 14 --many-faces --execution-provider cuda --frame-processor face_swapper face_enhancer --output-video-quality 35 --temp-frame-format jpg --max-memory 46')\n",
        "'''"
      ],
      "metadata": {
        "id": "hpfdp1UO4HQV",
        "collapsed": true,
        "outputId": "a8fc3e4d-8815-424f-efe4-73ca75b3e849",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the folder containing source images: /content/Source Folder/Untitled Folder\n",
            "Enter the path to the templates folder: /content/Target Folder/Doctor\n",
            "Processing target image: Doctor (3).png\n",
            "Processing target image: Doctor (5).png\n",
            "Processing target image: Doctor (6).png\n",
            "Processing target image: Doctor (4).png\n",
            "Processing target image: Doctor (1).png\n",
            "Processing target image: Doctor (2).png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python /content/roop/run.py -s \"/content/captain (9).jpg\" -t \"/content/LI (1).jpg\" -o \"/content/RG(Outputs)/\" --keep-fps --execution-threads 14 --many-faces --execution-provider cuda --frame-processor face_swapper face_enhancer --output-video-quality 35 --temp-frame-format jpg --max-memory 46\n"
      ],
      "metadata": {
        "id": "bTCrbw0qWB-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "def clone_repository(repo_url, target_directory):\n",
        "    try:\n",
        "        # Clone the repository\n",
        "        os.system(f'git clone {repo_url} {target_directory}')\n",
        "        print(\"Repository cloned successfully.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error while cloning repository:\", e)\n",
        "\n",
        "def process_images(source_image_path, output_folder):\n",
        "    templates_folder_path = \"/content/templates\"  # Provide the path to your templates folder here\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Randomly select one source image\n",
        "    selected_source_image_path = source_image_path\n",
        "\n",
        "    # Iterate over target images in the templates folder\n",
        "    for target_image_name in os.listdir(templates_folder_path):\n",
        "        target_image_path = os.path.join(templates_folder_path, target_image_name)\n",
        "\n",
        "        # Check if the item in the folder is a file\n",
        "        if os.path.isfile(target_image_path):\n",
        "            print(\"Processing target image:\", target_image_name)\n",
        "\n",
        "            # Run the command for each target image\n",
        "            os.system(f'python /content/roop/run.py -s \"{selected_source_image_path}\" -t \"{target_image_path}\" -o \"{output_folder}\" --keep-fps --execution-threads 14 --many-faces --execution-provider cuda --frame-processor face_swapper face_enhancer --output-video-quality 35 --temp-frame-format jpg --max-memory 46')\n",
        "\n",
        "@app.route('/face_swap', methods=['POST'])\n",
        "def face_swap():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({'error': 'No file part'})\n",
        "\n",
        "    file = request.files['file']\n",
        "    if file.filename == '':\n",
        "        return jsonify({'error': 'No selected file'})\n",
        "\n",
        "    # Save the uploaded image\n",
        "    source_image_path = \"/content/uploaded Image\"\n",
        "    file.save(source_image_path)\n",
        "\n",
        "    # Process the uploaded image\n",
        "    output_folder = \"/content/output image\"\n",
        "    process_images(source_image_path, output_folder)\n",
        "\n",
        "    # Return the path to the output image\n",
        "    output_image_path = os.path.join(output_folder, \"output.jpg\")\n",
        "    return jsonify({'output_image_path': output_image_path})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Clone the repository and change directory\n",
        "    repo_url = \"https://github.com/girinath18/roop.git\"\n",
        "    target_directory = \"/content/roop\"\n",
        "    clone_repository(repo_url, target_directory)\n",
        "    os.chdir(target_directory)\n",
        "\n",
        "    app.run(debug=True, port=5001)"
      ],
      "metadata": {
        "id": "ui2YAbypZlmX",
        "outputId": "218dc11b-ccb7-4fcf-8676-b14af271c965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository cloned successfully.\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5001\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_file_path = os.path.join(save_path, 'model.pth')\n",
        "torch.save(model.state_dict(), model_file_path)\n"
      ],
      "metadata": {
        "id": "RbkS11HmfW3I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}